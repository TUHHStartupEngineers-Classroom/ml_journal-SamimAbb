<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Abbasi" />


<title>03 Automated Machine Learning with H20 II</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


<link rel="stylesheet" href="style.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">MyLabJournal</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Index</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Journal
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="01_ml_fund.html">01 Machine Learning Fundamentals</a>
    </li>
    <li>
      <a href="02_ml_sup.html">02 Supervised ML</a>
    </li>
    <li>
      <a href="03_ml_aut.html">03 Automated Machine Learning with H20</a>
    </li>
    <li>
      <a href="04_perf_meas.html">04 Performance Measures</a>
    </li>
    <li>
      <a href="05_lime.html">05 LIME</a>
    </li>
    <li>
      <a href="06_dl.html">06 Deep Learning</a>
    </li>
  </ul>
</li>
<li>
  <a href="07_class_notes.html">Class notes</a>
</li>
<li>
  <a href="08_links.html">Links</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">03 Automated Machine Learning with H20 II</h1>
<h4 class="author">Abbasi</h4>
<h4 class="date">1/8/2021</h4>

</div>


<pre class="r"><code>rm(list = ls())</code></pre>
<pre class="r"><code>library(modeldata)
library(readr)
library(readxl)
library(modelr)</code></pre>
<pre><code>## 
## Attaching package: &#39;modelr&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:yardstick&#39;:
## 
##     mae, mape, rmse</code></pre>
<pre><code>## The following object is masked from &#39;package:broom&#39;:
## 
##     bootstrap</code></pre>
<pre class="r"><code>library(modeltools)</code></pre>
<pre><code>## Loading required package: stats4</code></pre>
<pre><code>## 
## Attaching package: &#39;modeltools&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:tune&#39;:
## 
##     parameters</code></pre>
<pre><code>## The following object is masked from &#39;package:parsnip&#39;:
## 
##     fit</code></pre>
<pre><code>## The following object is masked from &#39;package:dials&#39;:
## 
##     parameters</code></pre>
<pre class="r"><code>library(tidymodels)
library(magrittr)
library(dplyr)
library(sjmisc)</code></pre>
<pre><code>## 
## Attaching package: &#39;sjmisc&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:workflows&#39;:
## 
##     add_variables</code></pre>
<pre><code>## The following object is masked from &#39;package:purrr&#39;:
## 
##     is_empty</code></pre>
<pre><code>## The following object is masked from &#39;package:tidyr&#39;:
## 
##     replace_na</code></pre>
<pre><code>## The following object is masked from &#39;package:tibble&#39;:
## 
##     add_case</code></pre>
<pre class="r"><code>library(magrittr)
library(haven)
library(sjlabelled)</code></pre>
<pre><code>## 
## Attaching package: &#39;sjlabelled&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:haven&#39;:
## 
##     as_factor, read_sas, read_spss, read_stata, write_sas, zap_labels</code></pre>
<pre><code>## The following object is masked from &#39;package:forcats&#39;:
## 
##     as_factor</code></pre>
<pre><code>## The following object is masked from &#39;package:dplyr&#39;:
## 
##     as_label</code></pre>
<pre class="r"><code>library(rsample)
library(recipes)
library(rstanarm)</code></pre>
<pre><code>## Loading required package: Rcpp</code></pre>
<pre><code>## 
## Attaching package: &#39;Rcpp&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:rsample&#39;:
## 
##     populate</code></pre>
<pre><code>## This is rstanarm version 2.21.1</code></pre>
<pre><code>## - See https://mc-stan.org/rstanarm/articles/priors for changes to default priors!</code></pre>
<pre><code>## - Default priors may change, so it&#39;s safest to specify priors, even if equivalent to the defaults.</code></pre>
<pre><code>## - For execution on a local, multicore CPU with excess RAM we recommend calling</code></pre>
<pre><code>##   options(mc.cores = parallel::detectCores())</code></pre>
<pre class="r"><code>library(broom.mixed)
library(h2o)</code></pre>
<pre><code>## 
## ----------------------------------------------------------------------
## 
## Your next step is to start H2O:
##     &gt; h2o.init()
## 
## For H2O package documentation, ask for help:
##     &gt; ??h2o
## 
## After starting H2O, you can use the Web UI at http://localhost:54321
## For more information visit https://docs.h2o.ai
## 
## ----------------------------------------------------------------------</code></pre>
<pre><code>## 
## Attaching package: &#39;h2o&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:lubridate&#39;:
## 
##     day, hour, month, week, year</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     cor, sd, var</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     &amp;&amp;, %*%, %in%, ||, apply, as.factor, as.numeric, colnames,
##     colnames&lt;-, ifelse, is.character, is.factor, is.numeric, log,
##     log10, log1p, log2, round, signif, trunc</code></pre>
<pre class="r"><code>library(bayesplot)</code></pre>
<pre><code>## This is bayesplot version 1.7.2</code></pre>
<pre><code>## - Online documentation and vignettes at mc-stan.org/bayesplot</code></pre>
<pre><code>## - bayesplot theme set to bayesplot::theme_default()</code></pre>
<pre><code>##    * Does _not_ affect other ggplot2 plots</code></pre>
<pre><code>##    * See ?bayesplot_theme_set for details on theme setting</code></pre>
<pre class="r"><code>h2o.init()</code></pre>
<pre><code>##  Connection successful!
## 
## R is connected to the H2O cluster: 
##     H2O cluster uptime:         4 hours 11 minutes 
##     H2O cluster timezone:       Europe/Berlin 
##     H2O data parsing timezone:  UTC 
##     H2O cluster version:        3.32.0.1 
##     H2O cluster version age:    3 months and 1 day  
##     H2O cluster name:           H2O_started_from_R_abbasi_lcr825 
##     H2O cluster total nodes:    1 
##     H2O cluster total memory:   0.71 GB 
##     H2O cluster total cores:    4 
##     H2O cluster allowed cores:  4 
##     H2O cluster healthy:        TRUE 
##     H2O Connection ip:          localhost 
##     H2O Connection port:        54321 
##     H2O Connection proxy:       NA 
##     H2O Internal Security:      FALSE 
##     H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4 
##     R Version:                  R version 3.6.3 (2020-02-29)</code></pre>
<pre class="r"><code>theme_set(bayesplot::theme_default())
product_backorders_tbl &lt;- read_csv(&quot;/home/abbasi/Desktop/R/raw_data/product_backorders.csv&quot;) </code></pre>
<pre><code>## 
## ── Column specification ────────────────────────────────────────────────────────
## cols(
##   .default = col_double(),
##   potential_issue = col_character(),
##   deck_risk = col_character(),
##   oe_constraint = col_character(),
##   ppap_risk = col_character(),
##   stop_auto_buy = col_character(),
##   rev_stop = col_character(),
##   went_on_backorder = col_character()
## )
## ℹ Use `spec()` for the full column specifications.</code></pre>
<pre class="r"><code>product_backorders_tbl %&gt;% glimpse()</code></pre>
<pre><code>## Rows: 19,053
## Columns: 23
## $ sku               &lt;dbl&gt; 1113121, 1113268, 1113874, 1114222, 1114823, 111545…
## $ national_inv      &lt;dbl&gt; 0, 0, 20, 0, 0, 55, -34, 4, 2, -7, 1, 2, 0, 0, 0, 0…
## $ lead_time         &lt;dbl&gt; 8, 8, 2, 8, 12, 8, 8, 9, 8, 8, 8, 8, 12, 2, 12, 4, …
## $ in_transit_qty    &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, …
## $ forecast_3_month  &lt;dbl&gt; 6, 2, 45, 9, 31, 216, 120, 43, 4, 56, 2, 5, 5, 54, …
## $ forecast_6_month  &lt;dbl&gt; 6, 3, 99, 14, 31, 360, 240, 67, 6, 96, 4, 9, 6, 72,…
## $ forecast_9_month  &lt;dbl&gt; 6, 4, 153, 21, 31, 492, 240, 115, 9, 112, 6, 13, 9,…
## $ sales_1_month     &lt;dbl&gt; 0, 1, 16, 5, 7, 30, 83, 5, 1, 13, 0, 1, 0, 0, 1, 0,…
## $ sales_3_month     &lt;dbl&gt; 4, 2, 42, 17, 15, 108, 122, 22, 5, 30, 2, 5, 4, 0, …
## $ sales_6_month     &lt;dbl&gt; 9, 3, 80, 36, 33, 275, 144, 40, 6, 56, 3, 8, 5, 0, …
## $ sales_9_month     &lt;dbl&gt; 12, 3, 111, 43, 47, 340, 165, 58, 9, 76, 4, 11, 6, …
## $ min_bank          &lt;dbl&gt; 0, 0, 10, 0, 2, 51, 33, 4, 2, 0, 0, 0, 3, 4, 0, 0, …
## $ potential_issue   &lt;chr&gt; &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No…
## $ pieces_past_due   &lt;dbl&gt; 1, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …
## $ perf_6_month_avg  &lt;dbl&gt; 0.90, 0.96, 0.81, 0.96, 0.98, 0.00, 1.00, 0.69, 1.0…
## $ perf_12_month_avg &lt;dbl&gt; 0.89, 0.97, 0.88, 0.98, 0.98, 0.00, 0.97, 0.68, 0.9…
## $ local_bo_qty      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 34, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0,…
## $ deck_risk         &lt;chr&gt; &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No…
## $ oe_constraint     &lt;chr&gt; &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No…
## $ ppap_risk         &lt;chr&gt; &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;N…
## $ stop_auto_buy     &lt;chr&gt; &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Y…
## $ rev_stop          &lt;chr&gt; &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No…
## $ went_on_backorder &lt;chr&gt; &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Y…</code></pre>
<pre class="r"><code>data_split &lt;- initial_split(product_backorders_tbl, prop = 3/4)
# Assign training and test data
train_data &lt;- training(data_split)
test_data  &lt;- testing(data_split)

factor_names &lt;- c(&quot;went_on_backorder&quot;)
product_rec &lt;- 
  recipe(went_on_backorder ~ ., data = train_data) %&gt;%  
  step_dummy(all_nominal(), -all_outcomes()) %&gt;% 
  step_zv(all_predictors()) %&gt;% 
  step_mutate_at(went_on_backorder, fn = as.factor) %&gt;%
  prep()
d &lt;- summary(product_rec)

train_tbl &lt;- bake(product_rec, new_data = train_data)
test_tbl  &lt;- bake(product_rec, new_data = test_data)
#train_tbl &lt;- train(product_rec, new_data = train_data)
#test_tbl  &lt;- train(product_rec, new_data = test_data)</code></pre>
<div id="modeling" class="section level1">
<h1>Modeling</h1>
<pre class="r"><code># Split data into a training and a validation data frame
# Setting the seed is just for reproducability
split_h2o &lt;- h2o.splitFrame(as.h2o(train_tbl), ratios = c(0.75), seed = 1234)</code></pre>
<pre><code>## 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |======================================================================| 100%</code></pre>
<pre class="r"><code>train_h2o &lt;- split_h2o[[1]]
valid_h2o &lt;- split_h2o[[2]]
test_h2o  &lt;- as.h2o(test_tbl)</code></pre>
<pre><code>## 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |======================================================================| 100%</code></pre>
<pre class="r"><code># Set the target and predictors
y &lt;- &quot;went_on_backorder&quot;
x &lt;- setdiff(names(train_h2o), y)</code></pre>
<pre class="r"><code>automl_models_h2o &lt;- h2o.automl(
  x = x,
  y = y,
  training_frame    = train_h2o,
  validation_frame  = valid_h2o,
  leaderboard_frame = test_h2o,
  max_runtime_secs  = 30,
  nfolds            = 5 
)</code></pre>
<pre><code>## 
  |                                                                            
  |                                                                      |   0%
## 17:27:23.82: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.
  |                                                                            
  |===                                                                   |   5%
  |                                                                            
  |=======                                                               |  10%
  |                                                                            
  |==========                                                            |  14%
  |                                                                            
  |=============                                                         |  19%
  |                                                                            
  |=================                                                     |  24%
  |                                                                            
  |====================                                                  |  29%
  |                                                                            
  |=======================                                               |  33%
  |                                                                            
  |===========================                                           |  38%
  |                                                                            
  |==============================                                        |  43%
  |                                                                            
  |=================================                                     |  48%
  |                                                                            
  |=====================================                                 |  52%
  |                                                                            
  |========================================                              |  57%
  |                                                                            
  |===========================================                           |  62%
  |                                                                            
  |===============================================                       |  67%
  |                                                                            
  |==================================================                    |  72%
  |                                                                            
  |======================================================                |  77%
  |                                                                            
  |=========================================================             |  82%
  |                                                                            
  |============================================================          |  86%
  |                                                                            
  |=================================================================     |  92%
  |                                                                            
  |====================================================================  |  97%
  |                                                                            
  |======================================================================| 100%</code></pre>
<pre class="r"><code>typeof(automl_models_h2o)</code></pre>
<pre><code>## [1] &quot;S4&quot;</code></pre>
<pre class="r"><code>slotNames(automl_models_h2o)</code></pre>
<pre><code>## [1] &quot;project_name&quot;   &quot;leader&quot;         &quot;leaderboard&quot;    &quot;event_log&quot;     
## [5] &quot;modeling_steps&quot; &quot;training_info&quot;</code></pre>
<pre class="r"><code>automl_models_h2o@leaderboard </code></pre>
<pre><code>##                                              model_id       auc   logloss
## 1    StackedEnsemble_AllModels_AutoML_20210110_172723 0.9496133 0.1831590
## 2 StackedEnsemble_BestOfFamily_AutoML_20210110_172723 0.9479674 0.1848475
## 3      XGBoost_grid__1_AutoML_20210110_172723_model_2 0.9471685 0.1758009
## 4                    XGBoost_3_AutoML_20210110_172723 0.9458849 0.1816772
## 5      XGBoost_grid__1_AutoML_20210110_172723_model_1 0.9438265 0.2077032
## 6                    XGBoost_1_AutoML_20210110_172723 0.9431639 0.1872979
##       aucpr mean_per_class_error      rmse        mse
## 1 0.7583184            0.1532746 0.2279272 0.05195081
## 2 0.7543994            0.1593405 0.2288441 0.05236960
## 3 0.7557623            0.1452345 0.2271409 0.05159300
## 4 0.7493078            0.1545862 0.2303182 0.05304646
## 5 0.7475315            0.1620900 0.2358867 0.05564254
## 6 0.7401433            0.1651370 0.2312224 0.05346379
## 
## [18 rows x 7 columns]</code></pre>
<pre class="r"><code>automl_models_h2o@leader </code></pre>
<pre><code>## Model Details:
## ==============
## 
## H2OBinomialModel: stackedensemble
## Model ID:  StackedEnsemble_AllModels_AutoML_20210110_172723 
## Number of Base Models: 16
## 
## Base Models (count by algorithm type):
## 
## deeplearning          drf          gbm          glm      xgboost 
##            2            2            6            1            5 
## 
## Metalearner:
## 
## Metalearner algorithm: glm
## Metalearner cross-validation fold assignment:
##   Fold assignment scheme: AUTO
##   Number of folds: 5
##   Fold column: NULL
## Metalearner hyperparameters: 
## 
## 
## H2OBinomialMetrics: stackedensemble
## ** Reported on training data. **
## 
## MSE:  0.02633804
## RMSE:  0.16229
## LogLoss:  0.1010309
## Mean Per-Class Error:  0.07694259
## AUC:  0.9898162
## AUCPR:  0.9379838
## Gini:  0.9796325
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##          No  Yes    Error        Rate
## No     8624  191 0.021668   =191/8815
## Yes     158 1037 0.132218   =158/1195
## Totals 8782 1228 0.034865  =349/10010
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold       value idx
## 1                       max f1  0.301312    0.855964 228
## 2                       max f2  0.127380    0.890411 290
## 3                 max f0point5  0.617227    0.883833 144
## 4                 max accuracy  0.383634    0.965934 205
## 5                max precision  0.989138    1.000000   0
## 6                   max recall  0.031113    1.000000 358
## 7              max specificity  0.989138    1.000000   0
## 8             max absolute_mcc  0.301312    0.836235 228
## 9   max min_per_class_accuracy  0.119299    0.947280 293
## 10 max mean_per_class_accuracy  0.127380    0.948264 290
## 11                     max tns  0.989138 8815.000000   0
## 12                     max fns  0.989138 1189.000000   0
## 13                     max fps  0.017300 8815.000000 399
## 14                     max tps  0.031113 1195.000000 358
## 15                     max tnr  0.989138    1.000000   0
## 16                     max fnr  0.989138    0.994979   0
## 17                     max fpr  0.017300    1.000000 399
## 18                     max tpr  0.031113    1.000000 358
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`
## H2OBinomialMetrics: stackedensemble
## ** Reported on validation data. **
## 
## MSE:  0.05243317
## RMSE:  0.2289829
## LogLoss:  0.1853686
## Mean Per-Class Error:  0.1554511
## AUC:  0.9500951
## AUCPR:  0.7372304
## Gini:  0.9001903
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##          No Yes    Error       Rate
## No     2993 123 0.039474  =123/3116
## Yes     114 306 0.271429   =114/420
## Totals 3107 429 0.067025  =237/3536
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold       value idx
## 1                       max f1  0.312956    0.720848 215
## 2                       max f2  0.064128    0.778146 323
## 3                 max f0point5  0.644357    0.730958 132
## 4                 max accuracy  0.432890    0.932975 183
## 5                max precision  0.984905    1.000000   0
## 6                   max recall  0.020287    1.000000 383
## 7              max specificity  0.984905    1.000000   0
## 8             max absolute_mcc  0.312956    0.682818 215
## 9   max min_per_class_accuracy  0.065034    0.886072 322
## 10 max mean_per_class_accuracy  0.064128    0.889853 323
## 11                     max tns  0.984905 3116.000000   0
## 12                     max fns  0.984905  417.000000   0
## 13                     max fps  0.017216 3116.000000 399
## 14                     max tps  0.020287  420.000000 383
## 15                     max tnr  0.984905    1.000000   0
## 16                     max fnr  0.984905    0.992857   0
## 17                     max fpr  0.017216    1.000000 399
## 18                     max tpr  0.020287    1.000000 383
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`
## H2OBinomialMetrics: stackedensemble
## ** Reported on cross-validation data. **
## ** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **
## 
## MSE:  0.05075788
## RMSE:  0.2252951
## LogLoss:  0.177742
## Mean Per-Class Error:  0.1437119
## AUC:  0.9559685
## AUCPR:  0.7555146
## Gini:  0.911937
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##          No  Yes    Error        Rate
## No     9031  454 0.047865   =454/9485
## Yes     304  965 0.239559   =304/1269
## Totals 9335 1419 0.070485  =758/10754
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold       value idx
## 1                       max f1  0.215376    0.718006 250
## 2                       max f2  0.060298    0.781801 329
## 3                 max f0point5  0.552104    0.741396 150
## 4                 max accuracy  0.552104    0.933513 150
## 5                max precision  0.990484    1.000000   0
## 6                   max recall  0.020392    1.000000 386
## 7              max specificity  0.990484    1.000000   0
## 8             max absolute_mcc  0.215376    0.679254 250
## 9   max min_per_class_accuracy  0.066969    0.887823 324
## 10 max mean_per_class_accuracy  0.060298    0.893936 329
## 11                     max tns  0.990484 9485.000000   0
## 12                     max fns  0.990484 1266.000000   0
## 13                     max fps  0.015832 9485.000000 399
## 14                     max tps  0.020392 1269.000000 386
## 15                     max tnr  0.990484    1.000000   0
## 16                     max fnr  0.990484    0.997636   0
## 17                     max fpr  0.015832    1.000000 399
## 18                     max tpr  0.020392    1.000000 386
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`</code></pre>
<pre class="r"><code>h2o.getModel(&quot;XGBoost_2_AutoML_20210110_151619&quot;) %&gt;%
  h2o.saveModel(path = &quot;/home/abbasi/Desktop/R/h20_models/&quot;)</code></pre>
<pre><code>## [1] &quot;/home/abbasi/Desktop/R/h20_models/XGBoost_2_AutoML_20210110_151619&quot;</code></pre>
<pre class="r"><code>extract_h2o_model_name_by_position &lt;- function(h2o_leaderboard, n = 1, verbose = T) {
  
  model_name &lt;- h2o_leaderboard %&gt;%
    as_tibble() %&gt;%
    slice(n) %&gt;%
    pull(model_id)
  
  if (verbose) message(model_name)
  
  return(model_name)
  
}</code></pre>
<pre class="r"><code>stacked_ensemble_h2o &lt;- h2o.loadModel(&quot;/home/abbasi/Desktop/R/h20_models/XGBoost_2_AutoML_20210110_151619&quot;)
stacked_ensemble_h2o</code></pre>
<pre><code>## Model Details:
## ==============
## 
## H2OBinomialModel: xgboost
## Model ID:  XGBoost_2_AutoML_20210110_151619 
## Model Summary: 
##   number_of_trees
## 1               7
## 
## 
## H2OBinomialMetrics: xgboost
## ** Reported on training data. **
## 
## MSE:  0.05170138
## RMSE:  0.2273794
## LogLoss:  0.2010379
## Mean Per-Class Error:  0.1545412
## AUC:  0.9554946
## AUCPR:  0.7871143
## Gini:  0.9109892
## R^2:  0.5082694
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##          No  Yes    Error        Rate
## No     9117  353 0.037276   =353/9470
## Yes     349  935 0.271807   =349/1284
## Totals 9466 1288 0.065278  =702/10754
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold       value idx
## 1                       max f1  0.406062    0.727061 181
## 2                       max f2  0.246676    0.778210 246
## 3                 max f0point5  0.541181    0.758475 125
## 4                 max accuracy  0.446500    0.935745 165
## 5                max precision  0.910086    1.000000   0
## 6                   max recall  0.060674    1.000000 393
## 7              max specificity  0.910086    1.000000   0
## 8             max absolute_mcc  0.406062    0.689990 181
## 9   max min_per_class_accuracy  0.180152    0.884735 280
## 10 max mean_per_class_accuracy  0.152028    0.891319 297
## 11                     max tns  0.910086 9470.000000   0
## 12                     max fns  0.910086 1280.000000   0
## 13                     max fps  0.058001 9470.000000 399
## 14                     max tps  0.060674 1284.000000 393
## 15                     max tnr  0.910086    1.000000   0
## 16                     max fnr  0.910086    0.996885   0
## 17                     max fpr  0.058001    1.000000 399
## 18                     max tpr  0.060674    1.000000 393
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`
## H2OBinomialMetrics: xgboost
## ** Reported on validation data. **
## 
## MSE:  0.05402154
## RMSE:  0.2324253
## LogLoss:  0.2070915
## Mean Per-Class Error:  0.1342165
## AUC:  0.9489409
## AUCPR:  0.7730118
## Gini:  0.8978819
## R^2:  0.4922304
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##          No Yes    Error       Rate
## No     2920 188 0.060489  =188/3108
## Yes      89 339 0.207944    =89/428
## Totals 3009 527 0.078337  =277/3536
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold       value idx
## 1                       max f1  0.309145    0.709948 212
## 2                       max f2  0.183759    0.774908 271
## 3                 max f0point5  0.599714    0.736732 103
## 4                 max accuracy  0.472994    0.930147 149
## 5                max precision  0.910846    1.000000   0
## 6                   max recall  0.061152    1.000000 388
## 7              max specificity  0.910846    1.000000   0
## 8             max absolute_mcc  0.309145    0.670039 212
## 9   max min_per_class_accuracy  0.183759    0.883178 271
## 10 max mean_per_class_accuracy  0.183759    0.885443 271
## 11                     max tns  0.910846 3108.000000   0
## 12                     max fns  0.910846  425.000000   0
## 13                     max fps  0.058189 3108.000000 399
## 14                     max tps  0.061152  428.000000 388
## 15                     max tnr  0.910846    1.000000   0
## 16                     max fnr  0.910846    0.992991   0
## 17                     max fpr  0.058189    1.000000 399
## 18                     max tpr  0.061152    1.000000 388
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`
## H2OBinomialMetrics: xgboost
## ** Reported on cross-validation data. **
## ** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **
## 
## MSE:  0.05704017
## RMSE:  0.2388308
## LogLoss:  0.2106254
## Mean Per-Class Error:  0.159438
## AUC:  0.9345637
## AUCPR:  0.7104371
## Gini:  0.8691274
## R^2:  0.4574924
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##          No  Yes    Error        Rate
## No     8921  549 0.057973   =549/9470
## Yes     335  949 0.260903   =335/1284
## Totals 9256 1498 0.082202  =884/10754
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold       value idx
## 1                       max f1  0.316034    0.682243 203
## 2                       max f2  0.195158    0.755822 255
## 3                 max f0point5  0.549707    0.701431 119
## 4                 max accuracy  0.487735    0.925237 141
## 5                max precision  0.931201    1.000000   0
## 6                   max recall  0.037968    1.000000 395
## 7              max specificity  0.931201    1.000000   0
## 8             max absolute_mcc  0.316034    0.637846 203
## 9   max min_per_class_accuracy  0.154961    0.868532 277
## 10 max mean_per_class_accuracy  0.177377    0.872931 265
## 11                     max tns  0.931201 9470.000000   0
## 12                     max fns  0.931201 1282.000000   0
## 13                     max fps  0.034504 9470.000000 399
## 14                     max tps  0.037968 1284.000000 395
## 15                     max tnr  0.931201    1.000000   0
## 16                     max fnr  0.931201    0.998442   0
## 17                     max fpr  0.034504    1.000000 399
## 18                     max tpr  0.037968    1.000000 395
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`
## Cross-Validation Metrics Summary: 
##                 mean           sd cv_1_valid  cv_2_valid cv_3_valid cv_4_valid
## accuracy  0.92058873 0.0066864663  0.9149233   0.9200372  0.9177127  0.9181776
## auc         0.938005  0.006705982  0.9394884  0.94879794  0.9343411  0.9360093
## aucpr     0.71220315  0.019668516 0.72665095   0.7109404  0.6928942  0.6935226
## err       0.07941124 0.0066864663 0.08507671 0.079962805 0.08228731 0.08182241
## err_count      170.8      14.4118      183.0       172.0      177.0      176.0
##            cv_5_valid
## accuracy     0.932093
## auc        0.93138796
## aucpr      0.73700774
## err       0.067906976
## err_count       146.0
## 
## ---
##                   mean          sd cv_1_valid cv_2_valid cv_3_valid cv_4_valid
## pr_auc      0.71220315 0.019668516 0.72665095  0.7109404  0.6928942  0.6935226
## precision   0.64677143 0.037337147 0.61490685  0.6340694  0.6360544 0.63728815
## r2          0.45750687 0.018561155 0.47413337  0.4551105  0.4416085   0.437826
## recall      0.74686587 0.027333742   0.770428 0.78210115 0.72762644  0.7315175
## rmse        0.23880093 0.004193064   0.235209 0.23942548 0.24237373 0.24319325
## specificity 0.94413936 0.009830983  0.9345301 0.93875396  0.9435058  0.9435058
##             cv_5_valid
## pr_auc      0.73700774
## precision   0.71153843
## r2          0.47885606
## recall      0.72265625
## rmse        0.23380315
## specificity  0.9604013</code></pre>
<pre class="r"><code>predictions &lt;- h2o.predict(stacked_ensemble_h2o, newdata = as.h2o(test_tbl))</code></pre>
<pre><code>## 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |======================================================================| 100%
## 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |======================================================================| 100%</code></pre>
<pre class="r"><code>typeof(predictions)</code></pre>
<pre><code>## [1] &quot;environment&quot;</code></pre>
<pre class="r"><code>predictions_tbl &lt;- predictions %&gt;% as_tibble()
predictions_tbl</code></pre>
<pre><code>## # A tibble: 4,763 x 3
##    predict    No   Yes
##    &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt;
##  1 Yes     0.214 0.786
##  2 Yes     0.189 0.811
##  3 Yes     0.326 0.674
##  4 Yes     0.248 0.752
##  5 Yes     0.433 0.567
##  6 No      0.862 0.138
##  7 Yes     0.674 0.326
##  8 Yes     0.158 0.842
##  9 Yes     0.385 0.615
## 10 Yes     0.377 0.623
## # … with 4,753 more rows</code></pre>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
