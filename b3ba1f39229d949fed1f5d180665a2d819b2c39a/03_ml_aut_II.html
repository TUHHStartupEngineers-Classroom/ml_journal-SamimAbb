<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Abbasi" />


<title>03 Automated Machine Learning with H20 II</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>


<link rel="stylesheet" href="style.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">MyLabJournal</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Index</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Journal
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="01_ml_fund.html">01 Machine Learning Fundamentals</a>
    </li>
    <li>
      <a href="02_ml_sup.html">02 Supervised ML</a>
    </li>
    <li>
      <a href="03_ml_aut.html">03 Automated Machine Learning with H20</a>
    </li>
    <li>
      <a href="04_perf_meas.html">04 Performance Measures</a>
    </li>
    <li>
      <a href="05_lime.html">05 LIME</a>
    </li>
    <li>
      <a href="06_dl.html">06 Deep Learning</a>
    </li>
  </ul>
</li>
<li>
  <a href="07_class_notes.html">Class notes</a>
</li>
<li>
  <a href="08_links.html">Links</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">03 Automated Machine Learning with H20 II</h1>
<h4 class="author">Abbasi</h4>
<h4 class="date">1/8/2021</h4>

</div>


<pre class="r"><code>rm(list = ls())</code></pre>
<pre class="r"><code>library(modeldata)
library(readr)
library(readxl)
library(modelr)
library(modeltools)</code></pre>
<pre><code>## Loading required package: stats4</code></pre>
<pre class="r"><code>library(tidymodels)</code></pre>
<pre><code>## ── Attaching packages ────────────────────────────────────── tidymodels 0.1.2 ──</code></pre>
<pre><code>## ✓ broom     0.7.2      ✓ recipes   0.1.15
## ✓ dials     0.0.9      ✓ rsample   0.0.8 
## ✓ dplyr     1.0.2      ✓ tibble    3.0.4 
## ✓ ggplot2   3.3.3      ✓ tidyr     1.1.2 
## ✓ infer     0.5.3      ✓ tune      0.1.2 
## ✓ parsnip   0.1.4      ✓ workflows 0.2.1 
## ✓ purrr     0.3.4      ✓ yardstick 0.0.7</code></pre>
<pre><code>## ── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──
## x broom::bootstrap() masks modelr::bootstrap()
## x purrr::discard()   masks scales::discard()
## x dplyr::filter()    masks stats::filter()
## x parsnip::fit()     masks modeltools::fit()
## x dplyr::lag()       masks stats::lag()
## x yardstick::mae()   masks modelr::mae()
## x yardstick::mape()  masks modelr::mape()
## x tune::parameters() masks dials::parameters(), modeltools::parameters()
## x yardstick::rmse()  masks modelr::rmse()
## x yardstick::spec()  masks readr::spec()
## x recipes::step()    masks stats::step()
## x recipes::update()  masks stats4::update(), stats::update()</code></pre>
<pre class="r"><code>library(magrittr)</code></pre>
<pre><code>## 
## Attaching package: &#39;magrittr&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:tidyr&#39;:
## 
##     extract</code></pre>
<pre><code>## The following object is masked from &#39;package:purrr&#39;:
## 
##     set_names</code></pre>
<pre class="r"><code>library(dplyr)
library(sjmisc)</code></pre>
<pre><code>## 
## Attaching package: &#39;sjmisc&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:workflows&#39;:
## 
##     add_variables</code></pre>
<pre><code>## The following object is masked from &#39;package:tidyr&#39;:
## 
##     replace_na</code></pre>
<pre><code>## The following object is masked from &#39;package:tibble&#39;:
## 
##     add_case</code></pre>
<pre><code>## The following object is masked from &#39;package:purrr&#39;:
## 
##     is_empty</code></pre>
<pre class="r"><code>library(magrittr)
library(haven)
library(sjlabelled)</code></pre>
<pre><code>## 
## Attaching package: &#39;sjlabelled&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:haven&#39;:
## 
##     as_factor, read_sas, read_spss, read_stata, write_sas, zap_labels</code></pre>
<pre><code>## The following object is masked from &#39;package:dplyr&#39;:
## 
##     as_label</code></pre>
<pre class="r"><code>library(rsample)
library(recipes)
library(rstanarm)</code></pre>
<pre><code>## Loading required package: Rcpp</code></pre>
<pre><code>## 
## Attaching package: &#39;Rcpp&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:rsample&#39;:
## 
##     populate</code></pre>
<pre><code>## This is rstanarm version 2.21.1</code></pre>
<pre><code>## - See https://mc-stan.org/rstanarm/articles/priors for changes to default priors!</code></pre>
<pre><code>## - Default priors may change, so it&#39;s safest to specify priors, even if equivalent to the defaults.</code></pre>
<pre><code>## - For execution on a local, multicore CPU with excess RAM we recommend calling</code></pre>
<pre><code>##   options(mc.cores = parallel::detectCores())</code></pre>
<pre class="r"><code>library(broom.mixed)</code></pre>
<pre><code>## Registered S3 method overwritten by &#39;broom.mixed&#39;:
##   method      from 
##   tidy.gamlss broom</code></pre>
<pre class="r"><code>library(h2o)</code></pre>
<pre><code>## 
## ----------------------------------------------------------------------
## 
## Your next step is to start H2O:
##     &gt; h2o.init()
## 
## For H2O package documentation, ask for help:
##     &gt; ??h2o
## 
## After starting H2O, you can use the Web UI at http://localhost:54321
## For more information visit https://docs.h2o.ai
## 
## ----------------------------------------------------------------------</code></pre>
<pre><code>## 
## Attaching package: &#39;h2o&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     cor, sd, var</code></pre>
<pre><code>## The following objects are masked from &#39;package:base&#39;:
## 
##     &amp;&amp;, %*%, %in%, ||, apply, as.factor, as.numeric, colnames,
##     colnames&lt;-, ifelse, is.character, is.factor, is.numeric, log,
##     log10, log1p, log2, round, signif, trunc</code></pre>
<pre class="r"><code>library(bayesplot)</code></pre>
<pre><code>## This is bayesplot version 1.7.2</code></pre>
<pre><code>## - Online documentation and vignettes at mc-stan.org/bayesplot</code></pre>
<pre><code>## - bayesplot theme set to bayesplot::theme_default()</code></pre>
<pre><code>##    * Does _not_ affect other ggplot2 plots</code></pre>
<pre><code>##    * See ?bayesplot_theme_set for details on theme setting</code></pre>
<pre class="r"><code>h2o.init()</code></pre>
<pre><code>##  Connection successful!
## 
## R is connected to the H2O cluster: 
##     H2O cluster uptime:         3 hours 51 minutes 
##     H2O cluster timezone:       Europe/Berlin 
##     H2O data parsing timezone:  UTC 
##     H2O cluster version:        3.32.0.1 
##     H2O cluster version age:    3 months and 1 day  
##     H2O cluster name:           H2O_started_from_R_abbasi_lcr825 
##     H2O cluster total nodes:    1 
##     H2O cluster total memory:   0.91 GB 
##     H2O cluster total cores:    4 
##     H2O cluster allowed cores:  4 
##     H2O cluster healthy:        TRUE 
##     H2O Connection ip:          localhost 
##     H2O Connection port:        54321 
##     H2O Connection proxy:       NA 
##     H2O Internal Security:      FALSE 
##     H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, TargetEncoder, Core V4 
##     R Version:                  R version 3.6.3 (2020-02-29)</code></pre>
<pre class="r"><code>theme_set(bayesplot::theme_default())
product_backorders_tbl &lt;- read_csv(&quot;/home/abbasi/Desktop/R/raw_data/product_backorders.csv&quot;) </code></pre>
<pre><code>## 
## ── Column specification ────────────────────────────────────────────────────────
## cols(
##   .default = col_double(),
##   potential_issue = col_character(),
##   deck_risk = col_character(),
##   oe_constraint = col_character(),
##   ppap_risk = col_character(),
##   stop_auto_buy = col_character(),
##   rev_stop = col_character(),
##   went_on_backorder = col_character()
## )
## ℹ Use `spec()` for the full column specifications.</code></pre>
<pre class="r"><code>product_backorders_tbl %&gt;% glimpse()</code></pre>
<pre><code>## Rows: 19,053
## Columns: 23
## $ sku               &lt;dbl&gt; 1113121, 1113268, 1113874, 1114222, 1114823, 111545…
## $ national_inv      &lt;dbl&gt; 0, 0, 20, 0, 0, 55, -34, 4, 2, -7, 1, 2, 0, 0, 0, 0…
## $ lead_time         &lt;dbl&gt; 8, 8, 2, 8, 12, 8, 8, 9, 8, 8, 8, 8, 12, 2, 12, 4, …
## $ in_transit_qty    &lt;dbl&gt; 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, …
## $ forecast_3_month  &lt;dbl&gt; 6, 2, 45, 9, 31, 216, 120, 43, 4, 56, 2, 5, 5, 54, …
## $ forecast_6_month  &lt;dbl&gt; 6, 3, 99, 14, 31, 360, 240, 67, 6, 96, 4, 9, 6, 72,…
## $ forecast_9_month  &lt;dbl&gt; 6, 4, 153, 21, 31, 492, 240, 115, 9, 112, 6, 13, 9,…
## $ sales_1_month     &lt;dbl&gt; 0, 1, 16, 5, 7, 30, 83, 5, 1, 13, 0, 1, 0, 0, 1, 0,…
## $ sales_3_month     &lt;dbl&gt; 4, 2, 42, 17, 15, 108, 122, 22, 5, 30, 2, 5, 4, 0, …
## $ sales_6_month     &lt;dbl&gt; 9, 3, 80, 36, 33, 275, 144, 40, 6, 56, 3, 8, 5, 0, …
## $ sales_9_month     &lt;dbl&gt; 12, 3, 111, 43, 47, 340, 165, 58, 9, 76, 4, 11, 6, …
## $ min_bank          &lt;dbl&gt; 0, 0, 10, 0, 2, 51, 33, 4, 2, 0, 0, 0, 3, 4, 0, 0, …
## $ potential_issue   &lt;chr&gt; &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No…
## $ pieces_past_due   &lt;dbl&gt; 1, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …
## $ perf_6_month_avg  &lt;dbl&gt; 0.90, 0.96, 0.81, 0.96, 0.98, 0.00, 1.00, 0.69, 1.0…
## $ perf_12_month_avg &lt;dbl&gt; 0.89, 0.97, 0.88, 0.98, 0.98, 0.00, 0.97, 0.68, 0.9…
## $ local_bo_qty      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 34, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0,…
## $ deck_risk         &lt;chr&gt; &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No…
## $ oe_constraint     &lt;chr&gt; &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No…
## $ ppap_risk         &lt;chr&gt; &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;Yes&quot;, &quot;No&quot;, &quot;No&quot;, &quot;N…
## $ stop_auto_buy     &lt;chr&gt; &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Y…
## $ rev_stop          &lt;chr&gt; &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No&quot;, &quot;No…
## $ went_on_backorder &lt;chr&gt; &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Yes&quot;, &quot;Y…</code></pre>
<pre class="r"><code>data_split &lt;- initial_split(product_backorders_tbl, prop = 3/4)
# Assign training and test data
train_data &lt;- training(data_split)
test_data  &lt;- testing(data_split)

factor_names &lt;- c(&quot;went_on_backorder&quot;)
product_rec &lt;- 
  recipe(went_on_backorder ~ ., data = train_data) %&gt;%  
  step_dummy(all_nominal(), -all_outcomes()) %&gt;% 
  step_zv(all_predictors()) %&gt;% 
  step_mutate_at(went_on_backorder, fn = as.factor) %&gt;%
  prep()
d &lt;- summary(product_rec)

train_tbl &lt;- bake(product_rec, new_data = train_data)
test_tbl  &lt;- bake(product_rec, new_data = test_data)
#train_tbl &lt;- train(product_rec, new_data = train_data)
#test_tbl  &lt;- train(product_rec, new_data = test_data)</code></pre>
<div id="modeling" class="section level1">
<h1>Modeling</h1>
<pre class="r"><code># Split data into a training and a validation data frame
# Setting the seed is just for reproducability
split_h2o &lt;- h2o.splitFrame(as.h2o(train_tbl), ratios = c(0.75), seed = 1234)</code></pre>
<pre><code>## 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |======================================================================| 100%</code></pre>
<pre class="r"><code>train_h2o &lt;- split_h2o[[1]]
valid_h2o &lt;- split_h2o[[2]]
test_h2o  &lt;- as.h2o(test_tbl)</code></pre>
<pre><code>## 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |======================================================================| 100%</code></pre>
<pre class="r"><code># Set the target and predictors
y &lt;- &quot;went_on_backorder&quot;
x &lt;- setdiff(names(train_h2o), y)</code></pre>
<pre class="r"><code>automl_models_h2o &lt;- h2o.automl(
  x = x,
  y = y,
  training_frame    = train_h2o,
  validation_frame  = valid_h2o,
  leaderboard_frame = test_h2o,
  max_runtime_secs  = 30,
  nfolds            = 5 
)</code></pre>
<pre><code>## 
  |                                                                            
  |                                                                      |   0%
## 17:07:26.453: User specified a validation frame with cross-validation still enabled. Please note that the models will still be validated using cross-validation only, the validation frame will be used to provide purely informative validation metrics on the trained models.
  |                                                                            
  |====                                                                  |   5%
  |                                                                            
  |=======                                                               |  10%
  |                                                                            
  |==========                                                            |  14%
  |                                                                            
  |=============                                                         |  19%
  |                                                                            
  |================                                                      |  23%
  |                                                                            
  |====================                                                  |  28%
  |                                                                            
  |=======================                                               |  33%
  |                                                                            
  |==========================                                            |  37%
  |                                                                            
  |=============================                                         |  42%
  |                                                                            
  |=================================                                     |  47%
  |                                                                            
  |====================================                                  |  51%
  |                                                                            
  |=======================================                               |  56%
  |                                                                            
  |===========================================                           |  61%
  |                                                                            
  |==============================================                        |  66%
  |                                                                            
  |=================================================                     |  71%
  |                                                                            
  |=====================================================                 |  75%
  |                                                                            
  |========================================================              |  80%
  |                                                                            
  |===========================================================           |  85%
  |                                                                            
  |===============================================================       |  90%
  |                                                                            
  |======================================================================| 100%</code></pre>
<pre class="r"><code>typeof(automl_models_h2o)</code></pre>
<pre><code>## [1] &quot;S4&quot;</code></pre>
<pre class="r"><code>slotNames(automl_models_h2o)</code></pre>
<pre><code>## [1] &quot;project_name&quot;   &quot;leader&quot;         &quot;leaderboard&quot;    &quot;event_log&quot;     
## [5] &quot;modeling_steps&quot; &quot;training_info&quot;</code></pre>
<pre class="r"><code>automl_models_h2o@leaderboard </code></pre>
<pre><code>##                                              model_id       auc   logloss
## 1      XGBoost_grid__1_AutoML_20210110_170726_model_2 0.9560657 0.1614488
## 2    StackedEnsemble_AllModels_AutoML_20210110_170726 0.9553296 0.1729640
## 3 StackedEnsemble_BestOfFamily_AutoML_20210110_170726 0.9539584 0.1741985
## 4      XGBoost_grid__1_AutoML_20210110_170726_model_1 0.9535686 0.1628563
## 5                    XGBoost_1_AutoML_20210110_170726 0.9497604 0.1723810
## 6                    XGBoost_3_AutoML_20210110_170726 0.9467068 0.1741005
##       aucpr mean_per_class_error      rmse        mse
## 1 0.7667516            0.1395265 0.2174721 0.04729413
## 2 0.7591199            0.1234868 0.2192262 0.04806012
## 3 0.7558637            0.1382340 0.2197151 0.04827471
## 4 0.7664965            0.1597085 0.2184954 0.04774023
## 5 0.7392636            0.1395536 0.2227865 0.04963381
## 6 0.7522396            0.1524893 0.2228894 0.04967969
## 
## [19 rows x 7 columns]</code></pre>
<pre class="r"><code>automl_models_h2o@leader </code></pre>
<pre><code>## Model Details:
## ==============
## 
## H2OBinomialModel: xgboost
## Model ID:  XGBoost_grid__1_AutoML_20210110_170726_model_2 
## Model Summary: 
##   number_of_trees
## 1              34
## 
## 
## H2OBinomialMetrics: xgboost
## ** Reported on training data. **
## 
## MSE:  0.03619354
## RMSE:  0.190246
## LogLoss:  0.1251406
## Mean Per-Class Error:  0.11456
## AUC:  0.9753753
## AUCPR:  0.8718063
## Gini:  0.9507506
## R^2:  0.6559957
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##          No  Yes    Error        Rate
## No     9208  261 0.027564   =261/9469
## Yes     259 1026 0.201556   =259/1285
## Totals 9467 1287 0.048354  =520/10754
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold       value idx
## 1                       max f1  0.405142    0.797823 180
## 2                       max f2  0.173676    0.840222 258
## 3                 max f0point5  0.642761    0.826642 114
## 4                 max accuracy  0.464165    0.951832 164
## 5                max precision  0.993270    1.000000   0
## 6                   max recall  0.002945    1.000000 392
## 7              max specificity  0.993270    1.000000   0
## 8             max absolute_mcc  0.405142    0.770362 180
## 9   max min_per_class_accuracy  0.162713    0.921745 263
## 10 max mean_per_class_accuracy  0.152980    0.922996 266
## 11                     max tns  0.993270 9469.000000   0
## 12                     max fns  0.993270 1277.000000   0
## 13                     max fps  0.000960 9469.000000 399
## 14                     max tps  0.002945 1285.000000 392
## 15                     max tnr  0.993270    1.000000   0
## 16                     max fnr  0.993270    0.993774   0
## 17                     max fpr  0.000960    1.000000 399
## 18                     max tpr  0.002945    1.000000 392
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`
## H2OBinomialMetrics: xgboost
## ** Reported on validation data. **
## 
## MSE:  0.05546809
## RMSE:  0.2355167
## LogLoss:  0.1871092
## Mean Per-Class Error:  0.1462436
## AUC:  0.9459807
## AUCPR:  0.6982021
## Gini:  0.8919614
## R^2:  0.4796816
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##          No Yes    Error       Rate
## No     2908 199 0.064049  =199/3107
## Yes      98 331 0.228438    =98/429
## Totals 3006 530 0.083993  =297/3536
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold       value idx
## 1                       max f1  0.259785    0.690302 227
## 2                       max f2  0.109334    0.783751 290
## 3                 max f0point5  0.517468    0.701706 146
## 4                 max accuracy  0.517468    0.924774 146
## 5                max precision  0.994974    1.000000   0
## 6                   max recall  0.001617    1.000000 394
## 7              max specificity  0.994974    1.000000   0
## 8             max absolute_mcc  0.156571    0.650956 267
## 9   max min_per_class_accuracy  0.109334    0.890443 290
## 10 max mean_per_class_accuracy  0.076564    0.893749 310
## 11                     max tns  0.994974 3107.000000   0
## 12                     max fns  0.994974  428.000000   0
## 13                     max fps  0.000814 3107.000000 399
## 14                     max tps  0.001617  429.000000 394
## 15                     max tnr  0.994974    1.000000   0
## 16                     max fnr  0.994974    0.997669   0
## 17                     max fpr  0.000814    1.000000 399
## 18                     max tpr  0.001617    1.000000 394
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`
## H2OBinomialMetrics: xgboost
## ** Reported on cross-validation data. **
## ** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **
## 
## MSE:  0.05203207
## RMSE:  0.2281054
## LogLoss:  0.175985
## Mean Per-Class Error:  0.1483364
## AUC:  0.9471067
## AUCPR:  0.744803
## Gini:  0.8942133
## R^2:  0.5054572
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##          No  Yes    Error        Rate
## No     8981  488 0.051537   =488/9469
## Yes     315  970 0.245136   =315/1285
## Totals 9296 1458 0.074670  =803/10754
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold       value idx
## 1                       max f1  0.317065    0.707255 213
## 2                       max f2  0.141777    0.774500 275
## 3                 max f0point5  0.673827    0.719044 103
## 4                 max accuracy  0.438527    0.928678 175
## 5                max precision  0.994711    1.000000   0
## 6                   max recall  0.001010    1.000000 398
## 7              max specificity  0.994711    1.000000   0
## 8             max absolute_mcc  0.317065    0.666399 213
## 9   max min_per_class_accuracy  0.107502    0.881712 292
## 10 max mean_per_class_accuracy  0.087832    0.884732 304
## 11                     max tns  0.994711 9469.000000   0
## 12                     max fns  0.994711 1283.000000   0
## 13                     max fps  0.000674 9469.000000 399
## 14                     max tps  0.001010 1285.000000 398
## 15                     max tnr  0.994711    1.000000   0
## 16                     max fnr  0.994711    0.998444   0
## 17                     max fpr  0.000674    1.000000 399
## 18                     max tpr  0.001010    1.000000 398
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`
## Cross-Validation Metrics Summary: 
##                 mean           sd  cv_1_valid cv_2_valid cv_3_valid  cv_4_valid
## accuracy  0.92858416  0.006587486   0.9381683  0.9321246  0.9270107   0.9228266
## auc        0.9474567 0.0063184896  0.95514095  0.9459865  0.9513331  0.94644564
## aucpr      0.7467333   0.02424171  0.78776306  0.7254104  0.7418231  0.74561816
## err       0.07141583  0.006587486 0.061831705 0.06787541 0.07298931 0.077173404
## err_count      153.6    14.152739       133.0      146.0      157.0       166.0
##           cv_5_valid
## accuracy   0.9227907
## auc        0.9383773
## aucpr      0.7330519
## err        0.0772093
## err_count      166.0
## 
## ---
##                   mean           sd cv_1_valid cv_2_valid cv_3_valid cv_4_valid
## pr_auc       0.7467333   0.02424171 0.78776306  0.7254104  0.7418231 0.74561816
## precision   0.68421364  0.024570625 0.71985817  0.6989247  0.6736111  0.6678967
## r2           0.5054568   0.03273388  0.5582655  0.5041973 0.50812596 0.48140797
## recall       0.7470817  0.032554865 0.78988326 0.75875485  0.7548638 0.70428014
## rmse        0.22800304 0.0076630595  0.2155742 0.22838658 0.22747993 0.23357645
## specificity 0.95321536  0.003732962  0.9582893 0.95564944  0.9503696  0.9524815
##             cv_5_valid
## pr_auc       0.7330519
## precision    0.6607774
## r2          0.47528714
## recall      0.72762644
## rmse        0.23499805
## specificity  0.9492868</code></pre>
<pre class="r"><code>h2o.getModel(&quot;XGBoost_2_AutoML_20210110_151619&quot;) %&gt;%
  h2o.saveModel(path = &quot;/home/abbasi/Desktop/R/h20_models/&quot;)</code></pre>
<pre><code>## [1] &quot;/home/abbasi/Desktop/R/h20_models/XGBoost_2_AutoML_20210110_151619&quot;</code></pre>
<pre class="r"><code>extract_h2o_model_name_by_position &lt;- function(h2o_leaderboard, n = 1, verbose = T) {
  
  model_name &lt;- h2o_leaderboard %&gt;%
    as_tibble() %&gt;%
    slice(n) %&gt;%
    pull(model_id)
  
  if (verbose) message(model_name)
  
  return(model_name)
  
}</code></pre>
<pre class="r"><code>stacked_ensemble_h2o &lt;- h2o.loadModel(&quot;/home/abbasi/Desktop/R/h20_models/XGBoost_2_AutoML_20210110_151619&quot;)
stacked_ensemble_h2o</code></pre>
<pre><code>## Model Details:
## ==============
## 
## H2OBinomialModel: xgboost
## Model ID:  XGBoost_2_AutoML_20210110_151619 
## Model Summary: 
##   number_of_trees
## 1               7
## 
## 
## H2OBinomialMetrics: xgboost
## ** Reported on training data. **
## 
## MSE:  0.05170138
## RMSE:  0.2273794
## LogLoss:  0.2010379
## Mean Per-Class Error:  0.1545412
## AUC:  0.9554946
## AUCPR:  0.7871143
## Gini:  0.9109892
## R^2:  0.5082694
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##          No  Yes    Error        Rate
## No     9117  353 0.037276   =353/9470
## Yes     349  935 0.271807   =349/1284
## Totals 9466 1288 0.065278  =702/10754
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold       value idx
## 1                       max f1  0.406062    0.727061 181
## 2                       max f2  0.246676    0.778210 246
## 3                 max f0point5  0.541181    0.758475 125
## 4                 max accuracy  0.446500    0.935745 165
## 5                max precision  0.910086    1.000000   0
## 6                   max recall  0.060674    1.000000 393
## 7              max specificity  0.910086    1.000000   0
## 8             max absolute_mcc  0.406062    0.689990 181
## 9   max min_per_class_accuracy  0.180152    0.884735 280
## 10 max mean_per_class_accuracy  0.152028    0.891319 297
## 11                     max tns  0.910086 9470.000000   0
## 12                     max fns  0.910086 1280.000000   0
## 13                     max fps  0.058001 9470.000000 399
## 14                     max tps  0.060674 1284.000000 393
## 15                     max tnr  0.910086    1.000000   0
## 16                     max fnr  0.910086    0.996885   0
## 17                     max fpr  0.058001    1.000000 399
## 18                     max tpr  0.060674    1.000000 393
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`
## H2OBinomialMetrics: xgboost
## ** Reported on validation data. **
## 
## MSE:  0.05402154
## RMSE:  0.2324253
## LogLoss:  0.2070915
## Mean Per-Class Error:  0.1342165
## AUC:  0.9489409
## AUCPR:  0.7730118
## Gini:  0.8978819
## R^2:  0.4922304
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##          No Yes    Error       Rate
## No     2920 188 0.060489  =188/3108
## Yes      89 339 0.207944    =89/428
## Totals 3009 527 0.078337  =277/3536
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold       value idx
## 1                       max f1  0.309145    0.709948 212
## 2                       max f2  0.183759    0.774908 271
## 3                 max f0point5  0.599714    0.736732 103
## 4                 max accuracy  0.472994    0.930147 149
## 5                max precision  0.910846    1.000000   0
## 6                   max recall  0.061152    1.000000 388
## 7              max specificity  0.910846    1.000000   0
## 8             max absolute_mcc  0.309145    0.670039 212
## 9   max min_per_class_accuracy  0.183759    0.883178 271
## 10 max mean_per_class_accuracy  0.183759    0.885443 271
## 11                     max tns  0.910846 3108.000000   0
## 12                     max fns  0.910846  425.000000   0
## 13                     max fps  0.058189 3108.000000 399
## 14                     max tps  0.061152  428.000000 388
## 15                     max tnr  0.910846    1.000000   0
## 16                     max fnr  0.910846    0.992991   0
## 17                     max fpr  0.058189    1.000000 399
## 18                     max tpr  0.061152    1.000000 388
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`
## H2OBinomialMetrics: xgboost
## ** Reported on cross-validation data. **
## ** 5-fold cross-validation on training data (Metrics computed for combined holdout predictions) **
## 
## MSE:  0.05704017
## RMSE:  0.2388308
## LogLoss:  0.2106254
## Mean Per-Class Error:  0.159438
## AUC:  0.9345637
## AUCPR:  0.7104371
## Gini:  0.8691274
## R^2:  0.4574924
## 
## Confusion Matrix (vertical: actual; across: predicted) for F1-optimal threshold:
##          No  Yes    Error        Rate
## No     8921  549 0.057973   =549/9470
## Yes     335  949 0.260903   =335/1284
## Totals 9256 1498 0.082202  =884/10754
## 
## Maximum Metrics: Maximum metrics at their respective thresholds
##                         metric threshold       value idx
## 1                       max f1  0.316034    0.682243 203
## 2                       max f2  0.195158    0.755822 255
## 3                 max f0point5  0.549707    0.701431 119
## 4                 max accuracy  0.487735    0.925237 141
## 5                max precision  0.931201    1.000000   0
## 6                   max recall  0.037968    1.000000 395
## 7              max specificity  0.931201    1.000000   0
## 8             max absolute_mcc  0.316034    0.637846 203
## 9   max min_per_class_accuracy  0.154961    0.868532 277
## 10 max mean_per_class_accuracy  0.177377    0.872931 265
## 11                     max tns  0.931201 9470.000000   0
## 12                     max fns  0.931201 1282.000000   0
## 13                     max fps  0.034504 9470.000000 399
## 14                     max tps  0.037968 1284.000000 395
## 15                     max tnr  0.931201    1.000000   0
## 16                     max fnr  0.931201    0.998442   0
## 17                     max fpr  0.034504    1.000000 399
## 18                     max tpr  0.037968    1.000000 395
## 
## Gains/Lift Table: Extract with `h2o.gainsLift(&lt;model&gt;, &lt;data&gt;)` or `h2o.gainsLift(&lt;model&gt;, valid=&lt;T/F&gt;, xval=&lt;T/F&gt;)`
## Cross-Validation Metrics Summary: 
##                 mean           sd cv_1_valid  cv_2_valid cv_3_valid cv_4_valid
## accuracy  0.92058873 0.0066864663  0.9149233   0.9200372  0.9177127  0.9181776
## auc         0.938005  0.006705982  0.9394884  0.94879794  0.9343411  0.9360093
## aucpr     0.71220315  0.019668516 0.72665095   0.7109404  0.6928942  0.6935226
## err       0.07941124 0.0066864663 0.08507671 0.079962805 0.08228731 0.08182241
## err_count      170.8      14.4118      183.0       172.0      177.0      176.0
##            cv_5_valid
## accuracy     0.932093
## auc        0.93138796
## aucpr      0.73700774
## err       0.067906976
## err_count       146.0
## 
## ---
##                   mean          sd cv_1_valid cv_2_valid cv_3_valid cv_4_valid
## pr_auc      0.71220315 0.019668516 0.72665095  0.7109404  0.6928942  0.6935226
## precision   0.64677143 0.037337147 0.61490685  0.6340694  0.6360544 0.63728815
## r2          0.45750687 0.018561155 0.47413337  0.4551105  0.4416085   0.437826
## recall      0.74686587 0.027333742   0.770428 0.78210115 0.72762644  0.7315175
## rmse        0.23880093 0.004193064   0.235209 0.23942548 0.24237373 0.24319325
## specificity 0.94413936 0.009830983  0.9345301 0.93875396  0.9435058  0.9435058
##             cv_5_valid
## pr_auc      0.73700774
## precision   0.71153843
## r2          0.47885606
## recall      0.72265625
## rmse        0.23380315
## specificity  0.9604013</code></pre>
<pre class="r"><code>predictions &lt;- h2o.predict(stacked_ensemble_h2o, newdata = as.h2o(test_tbl))</code></pre>
<pre><code>## 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |======================================================================| 100%
## 
  |                                                                            
  |                                                                      |   0%
  |                                                                            
  |======================================================================| 100%</code></pre>
<pre class="r"><code>typeof(predictions)</code></pre>
<pre><code>## [1] &quot;environment&quot;</code></pre>
<pre class="r"><code>predictions_tbl &lt;- predictions %&gt;% as_tibble()
predictions_tbl</code></pre>
<pre><code>## # A tibble: 4,763 x 3
##    predict    No   Yes
##    &lt;fct&gt;   &lt;dbl&gt; &lt;dbl&gt;
##  1 Yes     0.168 0.832
##  2 No      0.839 0.161
##  3 Yes     0.403 0.597
##  4 Yes     0.158 0.842
##  5 Yes     0.175 0.825
##  6 Yes     0.682 0.318
##  7 Yes     0.184 0.816
##  8 Yes     0.417 0.583
##  9 Yes     0.145 0.855
## 10 Yes     0.635 0.365
## # … with 4,753 more rows</code></pre>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
